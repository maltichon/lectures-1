---
title: "Data in PDF files"
author: Blake Miller
output: html_document
---

For reasons that often escape my understanding, many governmental agencies do not release data in a machine-readable format; instead, they just upload a series of PDF files to their website. Similarly, textual documents (parliamentary speeches, press releases, etc.) are commonly released just in PDF format.

PDF (Portable Document Format) documents are just containers for a series of different types of objects (text, images, fonts, and metadata), stored in such a way that it can be displayed in exactly the same way across different operating systems.

Precisely because of its versatility, it is hard to come up with a single method to extract data contained in a PDF file. But there are two general cases, which we will cover today: table data (e.g. election results) and textual data (e.g. speeches). 

Note that all the cases below assume that the actual text or data is embedded as such in the document, and not just as images (e.g. scanned text). If you cannot select text or data in your document, and copy and paste somewhere else, the examples here unfortunately won't be useful. For those cases, other approaches based on OCR (Optical Character Recognization) would be more appropriate, but go beyond the scope of this course.

#### Extracting tables from PDF files

First, we'll learn how to use the [tabulizer package](https://github.com/ropensci/tabulizer), created by Thomas Leeper and currently maintained by Tom Paskhalis from LSE. It connects R to the [Tabula java library](https://github.com/tabulapdf/tabula), which can be used to extract tables from PDF documents.

Note that `tabulizer` depends on rJava, which can be somewhat complicated to install on a Windows computer. See [here](https://github.com/ropensci/tabulizer#installation) for instructions on how to install it in your own laptop.

The first example will be relatively easy -- the file `2016results.pdf` contains the certified election results for the 2016 presidential election. The goal here is to extract the table on the first page. We will use the `extract_tables` function.

```{r}
library(tabulizer)
d <- extract_tables("2016results.pdf", pages=1)
```

Note that `tabula` is sufficiently smart to extract only the table and discard the rest.

Also note that `extract_tables` will return a list of data frames, so we'll have to select just the first element.

```{r}
results <- d[[1]]
```

As usual, we will need to clean the data -- removing the first and last row, assigning variable names, removing characters from numeric elements...

```{r}
results <- results[-c(1, nrow(results)),]
results <- data.frame(results, stringsAsFactors=F)
names(results) <- c("state", "total", "trump", "clinton")
results$trump <- gsub(" .*$", "", results$trump)
results$clinton <- gsub(" .*$", "", results$clinton)
```

Let's now check what states did each candidate win:

```{r}
results$state[results$clinton > results$trump]
results$state[results$clinton < results$trump]
```

Let's now work on a more complex example. What happens when there are multiple tables in the same page? `tabulizer` has an interactive tool that will help you identify the specific parts of a page that contain the table, the `extract_areas` function. It will display a viewer window where you can see the entire page, and then you can select the part of the page that contains the table.

```{r, eval=FALSE}
d <- extract_areas("multiple-tables.pdf")
```

In this case it may not be as useful, because the regular `extract_tables` would have also worked, but for very large pages, or when you want to modify the default selected area, this can come in handy:

```{r}
d <- extract_tables("multiple-tables.pdf")
tab <- d[[3]][-(1:2),]
performance <- as.numeric(substr(tab[,3], 1, 6))
# and now produce a bar plot
par(mai=c(1,2,1,1))
barplot( performance, names = tab[,1], horiz=TRUE, las=1)

```

